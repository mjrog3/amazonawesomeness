{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**\n",
    "\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the path to get to your CDs_and_Vinyl folder below\n",
    "PATH_TO_CDS = '../devided_dataset_v2/CDs_and_Vinyl/'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Open and load json training files\n",
    "x = pd.read_json(PATH_TO_CDS + 'train\\\\review_training.json')\n",
    "y = pd.read_json(PATH_TO_CDS + 'train\\\\product_training.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import sentiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PATCH TO SPEED UP (ONLY IF INTEL CHIP) \n",
    "\n",
    "lmao rip daniel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn \n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z = pd.merge(x,y,'inner','asin')\n",
    "#zgrouped = z.groupby(\"asin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x #770786 entries\n",
    "y #073082 entries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature creation testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a single feature ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewCount = x.groupby('asin')[\"reviewerID\"].count()\n",
    "reviewCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unixReviewMean = x.groupby('asin')['unixReviewTime'].mean()\n",
    "unixReviewMean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropUnverified = x[x.verified != True]\n",
    "dropUnverified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "groupby() testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = range(5)\n",
    "unique_items = z[\"asin\"].nunique()\n",
    "print(\"ui: \", unique_items)\n",
    "\n",
    "asin = z[\"asin\"].values\n",
    "print(\"asin: \",asin)\n",
    "avg_votes = np.zeros(len(asin))\n",
    "\n",
    "for i in tests: # eventually all\n",
    "    item = zgrouped.get_group(asin[i])\n",
    "    avg_votes[i] = item[\"vote\"].fillna(0).astype(int).mean()\n",
    "\n",
    "print(\"avg_votes: \", avg_votes[0:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function for sentiment\n",
    "def review_sentiment(text):\n",
    "    sia = sentiment.SentimentIntensityAnalyzer()\n",
    "    return sia.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "## just some examples to gut check\n",
    "print(review_sentiment(\"Ugh, what a terrible, horrible, no good, very bad day\"))\n",
    "print(review_sentiment(\"I went to the store today\"))\n",
    "print(review_sentiment(\"I absolutely love my favorite best friend\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply sentiment analysis to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = range(1)\n",
    "unique_items = z[\"asin\"].nunique()\n",
    "print(\"ui: \", unique_items)\n",
    "\n",
    "asin = z[\"asin\"].unique()\n",
    "# print(\"asin: \",asin[tests])\n",
    "avg_votes = np.zeros(len(asin))\n",
    "\n",
    "for i in tests: # eventually all\n",
    "    item = zgrouped.get_group(asin[i])\n",
    "    avg_votes[i] = item[\"vote\"].fillna(0).astype(int).mean()\n",
    "    print(len(item))\n",
    "    sentiments = map(review_sentiment,item[\"reviewText\"].values[0:1000])\n",
    "    \n",
    "    print(list(sentiments))\n",
    "\n",
    "print(\"avg_votes: \", avg_votes[0:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test example: \n",
    "\n",
    "*Gaussian Naive Bayes with tfidf*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "#split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=0)\n",
    "\n",
    "#train and apply tfidf\n",
    "    # fit = make vocab \n",
    "    # transform = turn words -> numbers\n",
    "x_train = tfidf.fit_transform(x_train).toarray()\n",
    "x_test = tfidf.transform(x_test).toarray()\n",
    "\n",
    "#make prediction\n",
    "y_pred = gnb.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "#print accuracy\n",
    "print(f\"Number of mislabeled points out of a total {x_test.shape[0]} points : {(y_test != y_pred).sum()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "(choose one)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVC(kernel='rbf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "#choose from 'entropy', 'gini', 'log_loss'\n",
    "criterion = 'entropy'\n",
    "\n",
    "    ###STOPPING CONDITIONS\n",
    "#max height/depth of the tree\n",
    "max_depth = 4\n",
    "\n",
    "#if sat(N) < n_samples*this, don't try to split it any further\n",
    "min_samples_split = .01\n",
    "\n",
    "    ###OTHER\n",
    "#if min(sat(nodes after a split)) < n_samples*this, split not considered \n",
    "#       (aka model isnt allowed to create leaf nodes with < n_samples*this samples)\n",
    "#       (smooths the model, avoids splits like 2000 -> 1999 vs 1)\n",
    "min_samples_leaf = .01\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference: What x,y should look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "#iris.data\n",
    "#iris.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing prep\n",
    "\n",
    "Put feature vector with col 1 as 'asin' to *z*, answers to *y*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all individual features into one dataFrame\n",
    "\n",
    "#enter any features to be combined here! \n",
    "#   They must be pd dataFrames with the 'asin' column for this to work\n",
    "features = [reviewCount,unixReviewMean]\n",
    "\n",
    "z = x['asin']\n",
    "for f in features:\n",
    "    z = pd.merge(z,f,'inner','asin')\n",
    "\n",
    "#combine resultant data with correct answers \n",
    "temp = pd.merge(z,y,'inner','asin')\n",
    "\n",
    "#split into features (x) and awesomeness (y), which now row correspond but don't have an 'asin' col anymore\n",
    "merged_x = temp.drop(['asin','awesomeness'], axis=1)\n",
    "merged_y = temp[\"awesomeness\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree - See what it looks like! \n",
    "\n",
    "(only run if the model is a decision tree)\n",
    "\n",
    "*note: this trains the model on the whole dataset, so don't do before testing!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(merged_x,merged_y)\n",
    "tree.plot_tree(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold testing \n",
    "\n",
    "(set model to variable *model*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "\n",
    "#desired metrics\n",
    "scoring=['f1','accuracy','precision','recall']\n",
    "\n",
    "#number of \"folds\"\n",
    "k=10\n",
    "\n",
    "cv_results = cross_validate(model, merged_x, merged_y, cv=k, scoring=scoring)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hline = (\"-\"*40)\n",
    "\n",
    "#print means, stdevs\n",
    "print(hline+\"\\n\\tAVG, STDEV TEST RESULTS\\n\"+hline)\n",
    "print(\"\\t\\tMEAN\\t\\tSTDEV\")\n",
    "for m in scoring:\n",
    "        ind = (\"test_\"+m)\n",
    "        test = (m+\":\").ljust(10)\n",
    "        print(f\"{test}\\t{np.round(cv_results[ind].mean(),4)}\\t\\t{np.round(cv_results[ind].std(),4)}\")\n",
    "\n",
    "\n",
    "    ##print per test results (if you really want, uncomment)\n",
    "# print(\"\\n\")\n",
    "# print(hline+\"\\n\\tPER TEST RESULTS\\n\"+hline)\n",
    "# for i in range(k):\n",
    "#     print(f\"Test {i}:\")\n",
    "#     for m in scoring:\n",
    "#         ind = (\"test_\"+m)\n",
    "#         test = (m+\":\").ljust(10)\n",
    "#         print(f\"\\t{test} {np.round(cv_results[ind][i],5)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05c71520a0dcab027352e7e322df057036499e029a71d8bd9640db340c648db4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
