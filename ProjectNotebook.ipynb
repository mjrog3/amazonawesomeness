{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**\n",
    "\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maxrogal/Desktop/Machine Learning/amazonawesomeness\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "print(os.getcwd())\n",
    "current_folder = os.getcwd()\n",
    "CDs_folder = '../CDs_and_Vinyl'\n",
    "\n",
    "# Open and load json training files\n",
    "x = pd.read_json(os.path.join(current_folder, CDs_folder, 'train', 'review_training.json'))\n",
    "y = pd.read_json(os.path.join(current_folder, CDs_folder, 'train', 'product_training.json'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import sentiment\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6673F1740E03573BCD64238FE711FC69</td>\n",
       "      <td>9C856D4A18E1355783B3B28B7ECC1848</td>\n",
       "      <td>1451520000</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>12 31, 2015</td>\n",
       "      <td>{'Format:': ' MP3 Music'}</td>\n",
       "      <td>8D88BB79AAC50277AEE82FCFD77F6744</td>\n",
       "      <td>Finding the Beatles all over again - and bette...</td>\n",
       "      <td>I sit listening - with my jaw to the floor - H...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>690819436E20BB31657AF6B58B984DD4</td>\n",
       "      <td>6E9ABBD26A27C2B2851D1EC34A01CBDC</td>\n",
       "      <td>1113523200</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>04 15, 2005</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>8DC0611245A871AC51BBEEBB85F33A58</td>\n",
       "      <td>These guys can sing!  Such classic tunes...poi...</td>\n",
       "      <td>Under Appreciated....</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A680D4753F0CEA2252C168A6ACB2B623</td>\n",
       "      <td>B637C3C93E61094474710F456928BE9F</td>\n",
       "      <td>1126137600</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>09 8, 2005</td>\n",
       "      <td>None</td>\n",
       "      <td>2259386624CFA0EC53A75A50A9BB57A5</td>\n",
       "      <td>Snoop Doggy Dogg made a classic album, DoggySt...</td>\n",
       "      <td>DoggyStyle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F4A966F1FA340B16651D676BC246D227</td>\n",
       "      <td>AA7918E9410D650A076221C7B2934A09</td>\n",
       "      <td>954979200</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>04 6, 2000</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>7A65A155C993535BC99CBCB39E7161B5</td>\n",
       "      <td>Stevie Nicks Has had Her Moments. I Like Some ...</td>\n",
       "      <td>Pretty Good but a Bit Dated</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EF59DAF0C00319A48D4784266FD157EE</td>\n",
       "      <td>2293C9B7950A3356B95828419A677720</td>\n",
       "      <td>1477958400</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>11 1, 2016</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>C69A09446009C500B1364B7DB5510497</td>\n",
       "      <td>Great cd.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770781</th>\n",
       "      <td>BD91503308A437374C3254EDC8BC24CB</td>\n",
       "      <td>936ED23AF4D23943786BBD44D0F1114B</td>\n",
       "      <td>1136246400</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>01 3, 2006</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>AAB61000438939C8E6165CFCCF02A488</td>\n",
       "      <td>This was the first Simple Minds album that I b...</td>\n",
       "      <td>Their Most Fully Realized Artistic Studio Stat...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770782</th>\n",
       "      <td>9BC50277D18FAB423AD33C8CE4CC000D</td>\n",
       "      <td>EF922377A87E9D01F50065F2DA1722A8</td>\n",
       "      <td>1290556800</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11 24, 2010</td>\n",
       "      <td>None</td>\n",
       "      <td>0441BC4F6B7BD180769FDCDD8E603560</td>\n",
       "      <td>I have owned a CD copy of this show for at lea...</td>\n",
       "      <td>Forgettable R&amp;H</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770783</th>\n",
       "      <td>4062627CA1586E517520483964299349</td>\n",
       "      <td>E1F0B0EBC6A36F33301E4FD0B3D62D52</td>\n",
       "      <td>1311120000</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>07 20, 2011</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>8AB3EEBF23F3583A4396A57DB291D548</td>\n",
       "      <td>carnival of souls to me is bad i gave my cd aw...</td>\n",
       "      <td>Darren d.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770784</th>\n",
       "      <td>0AE44A6A9176E6A52507B6ABDDA80B00</td>\n",
       "      <td>DDDC81E6B8C3F8C91867F9AECB385135</td>\n",
       "      <td>1111968000</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>03 28, 2005</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>51B2E62E0A5864316BDB33FD4A729B37</td>\n",
       "      <td>This is an awesome slayer album. I love the th...</td>\n",
       "      <td>awesome slayer cd</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770785</th>\n",
       "      <td>E4CDE9C72DB665961BE969B082806619</td>\n",
       "      <td>27FDC1E110DB45E1A7E0CCEABECF8632</td>\n",
       "      <td>1105401600</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>01 11, 2005</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>A7487BE472C2B632FCE5F097B47F5DE0</td>\n",
       "      <td>Smile is Brian's gift to a sick and troubled w...</td>\n",
       "      <td>Music just doesn't get any better...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>770786 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    asin                        reviewerID   \n",
       "0       6673F1740E03573BCD64238FE711FC69  9C856D4A18E1355783B3B28B7ECC1848  \\\n",
       "1       690819436E20BB31657AF6B58B984DD4  6E9ABBD26A27C2B2851D1EC34A01CBDC   \n",
       "2       A680D4753F0CEA2252C168A6ACB2B623  B637C3C93E61094474710F456928BE9F   \n",
       "3       F4A966F1FA340B16651D676BC246D227  AA7918E9410D650A076221C7B2934A09   \n",
       "4       EF59DAF0C00319A48D4784266FD157EE  2293C9B7950A3356B95828419A677720   \n",
       "...                                  ...                               ...   \n",
       "770781  BD91503308A437374C3254EDC8BC24CB  936ED23AF4D23943786BBD44D0F1114B   \n",
       "770782  9BC50277D18FAB423AD33C8CE4CC000D  EF922377A87E9D01F50065F2DA1722A8   \n",
       "770783  4062627CA1586E517520483964299349  E1F0B0EBC6A36F33301E4FD0B3D62D52   \n",
       "770784  0AE44A6A9176E6A52507B6ABDDA80B00  DDDC81E6B8C3F8C91867F9AECB385135   \n",
       "770785  E4CDE9C72DB665961BE969B082806619  27FDC1E110DB45E1A7E0CCEABECF8632   \n",
       "\n",
       "        unixReviewTime  vote  verified   reviewTime   \n",
       "0           1451520000     9      True  12 31, 2015  \\\n",
       "1           1113523200     9     False  04 15, 2005   \n",
       "2           1126137600  None     False   09 8, 2005   \n",
       "3            954979200  None     False   04 6, 2000   \n",
       "4           1477958400  None      True   11 1, 2016   \n",
       "...                ...   ...       ...          ...   \n",
       "770781      1136246400    12      True   01 3, 2006   \n",
       "770782      1290556800  None     False  11 24, 2010   \n",
       "770783      1311120000     3     False  07 20, 2011   \n",
       "770784      1111968000     2     False  03 28, 2005   \n",
       "770785      1105401600  None     False  01 11, 2005   \n",
       "\n",
       "                            style                      reviewerName   \n",
       "0       {'Format:': ' MP3 Music'}  8D88BB79AAC50277AEE82FCFD77F6744  \\\n",
       "1        {'Format:': ' Audio CD'}  8DC0611245A871AC51BBEEBB85F33A58   \n",
       "2                            None  2259386624CFA0EC53A75A50A9BB57A5   \n",
       "3        {'Format:': ' Audio CD'}  7A65A155C993535BC99CBCB39E7161B5   \n",
       "4        {'Format:': ' Audio CD'}  C69A09446009C500B1364B7DB5510497   \n",
       "...                           ...                               ...   \n",
       "770781   {'Format:': ' Audio CD'}  AAB61000438939C8E6165CFCCF02A488   \n",
       "770782                       None  0441BC4F6B7BD180769FDCDD8E603560   \n",
       "770783   {'Format:': ' Audio CD'}  8AB3EEBF23F3583A4396A57DB291D548   \n",
       "770784   {'Format:': ' Audio CD'}  51B2E62E0A5864316BDB33FD4A729B37   \n",
       "770785   {'Format:': ' Audio CD'}  A7487BE472C2B632FCE5F097B47F5DE0   \n",
       "\n",
       "                                               reviewText   \n",
       "0       Finding the Beatles all over again - and bette...  \\\n",
       "1       These guys can sing!  Such classic tunes...poi...   \n",
       "2       Snoop Doggy Dogg made a classic album, DoggySt...   \n",
       "3       Stevie Nicks Has had Her Moments. I Like Some ...   \n",
       "4                                               Great cd.   \n",
       "...                                                   ...   \n",
       "770781  This was the first Simple Minds album that I b...   \n",
       "770782  I have owned a CD copy of this show for at lea...   \n",
       "770783  carnival of souls to me is bad i gave my cd aw...   \n",
       "770784  This is an awesome slayer album. I love the th...   \n",
       "770785  Smile is Brian's gift to a sick and troubled w...   \n",
       "\n",
       "                                                  summary image  \n",
       "0       I sit listening - with my jaw to the floor - H...  None  \n",
       "1                                   Under Appreciated....  None  \n",
       "2                                              DoggyStyle  None  \n",
       "3                             Pretty Good but a Bit Dated  None  \n",
       "4                                              Five Stars  None  \n",
       "...                                                   ...   ...  \n",
       "770781  Their Most Fully Realized Artistic Studio Stat...  None  \n",
       "770782                                    Forgettable R&H  None  \n",
       "770783                                          Darren d.  None  \n",
       "770784                                  awesome slayer cd  None  \n",
       "770785               Music just doesn't get any better...  None  \n",
       "\n",
       "[770786 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PATCH TO SPEED UP (ONLY IF INTEL CHIP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn \n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x #770786 rows <- # reviews\n",
    "y #073082 rows <- # products"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature creation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a sample set to test features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts = test sample 2 thousand reviews long\n",
    "ts = x[:2000]\n",
    "ts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropUnverified = x[x.verified == True]\n",
    "reviewCount = x.groupby('asin')[\"reviewerID\"].count()\n",
    "reviewCount = reviewCount.rename(\"Review_Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin\n",
       "0000B049F5B33CD310EB1AB236E20191    1.419682e+09\n",
       "00018184A9EC4D270219A296B2580303    1.445414e+09\n",
       "000281A9CAC43FF1F335726A390636DA    1.326499e+09\n",
       "00030884DF109F325638A6BFD5B13CFF    1.397896e+09\n",
       "000325BA25966B5FC701D5D2B5DBA4E0    1.363802e+09\n",
       "                                        ...     \n",
       "FFFDD3C72D23AF858D6E0ED92612370D    1.406650e+09\n",
       "FFFDDE284A73B29B320381487EC7DE9E    1.401192e+09\n",
       "FFFEB3EE2372807964F024707D50FB21    1.349050e+09\n",
       "FFFF4545AB232D81D0F9B208388BB7AA    1.434283e+09\n",
       "FFFF5A3D9CB0B40FF0FE6B95F05D26FE    1.498781e+09\n",
       "Name: unixReviewTime, Length: 63401, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropUnverified.groupby('asin')['unixReviewTime'].mean() #63401 rows! -> some products don't have ANY verified reviews"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percent verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_verified = dropUnverified.groupby(\"asin\")[\"reviewerID\"].count()\n",
    "percent_verified = percent_verified/reviewCount\n",
    "percent_verified = percent_verified.apply(lambda x: x if x > 0  else 0)\n",
    "percent_verified = percent_verified.rename(\"%_Verified\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping bots by time of post\n",
    "\n",
    "All the comments are encoded with the date only, no time, so this is not possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "droppedBots = x[x.unixReviewTime % 100 != 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of votes across reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_copy = x.copy(deep=True)\n",
    "total_review_num = x_copy.vote\n",
    "total_review_num = total_review_num.apply(lambda x: float(x.replace(\",\", \"\")) if type(x) == str  else 0)\n",
    "total_review_num = total_review_num.rename(\"vote\").to_frame()\n",
    "x_copy[\"vote\"] = total_review_num[\"vote\"]\n",
    "total_votes = x_copy.groupby('asin')[\"vote\"].sum(\"vote\")\n",
    "total_votes = total_votes.rename(\"Total_Votes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percent of reviews with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_image = x[x.image.astype('string') != \"None\"]\n",
    "with_image = with_image.groupby('asin')[\"image\"].count()\n",
    "with_image_percentage = with_image/reviewCount\n",
    "with_image_percentage = with_image_percentage.apply(lambda x: x if x > 0  else 0)\n",
    "#with_image_percentage = with_image_percentage[with_image_percentage > 0] # - to see how many reviews have at least one image\n",
    "with_image_percentage = with_image_percentage.rename(\"%_Image\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small group to test text analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = x.groupby(\"asin\").get_group(\"0000B049F5B33CD310EB1AB236E20191\")\n",
    "\n",
    "# np.mean(len(str(testdata[\"reviewText\"]).split()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of Reviews Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewlength = x.groupby('asin')[\"reviewText\"].apply(lambda x: x.str.split().str.len().mean())\n",
    "reviewlength = reviewlength.fillna(0).rename(\"Review_Length\")\n",
    "\n",
    "summarylength = x.groupby('asin')[\"summary\"].apply(lambda x: x.str.split().str.len().mean())\n",
    "summarylength = summarylength.fillna(0).rename(\"Summary_Length\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= 1\n",
    "\n",
    "def f(votes):\n",
    "    if (votes>a):\n",
    "        return 2\n",
    "    return 344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to_string'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12992/3629067703.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msia\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mRSentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"reviewText\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"compound\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mRSentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRSentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Review_sentiment\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zachg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4630\u001b[0m         \"\"\"\n\u001b[1;32m-> 4631\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4633\u001b[0m     def _reduce(\n",
      "\u001b[1;32mc:\\Users\\zachg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[1;31m# self.f is Callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zachg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zachg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12992/3629067703.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msia\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mRSentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"reviewText\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"compound\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mRSentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRSentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Review_sentiment\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'to_string'"
     ]
    }
   ],
   "source": [
    "# x=x[:200]\n",
    "# sia = sentiment.SentimentIntensityAnalyzer()\n",
    "# RSentiment = x[\"reviewText\"].apply(lambda x: sia.polarity_scores(x.to_string())[\"compound\"]) #sentiment per no avg\n",
    "# RSentiment = RSentiment.fillna(0).rename(\"Review_sentiment\") #make that col\n",
    "# #apply f(votes) to each element\n",
    "# #avg the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage Uppercase Feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_cap(str):\n",
    "#     stripped = ''.join(str.split())\n",
    "#     return sum(c.isupper() for c in ''.join(stripped))/len(stripped)\n",
    "\n",
    "RpercentCap = x.groupby('asin')[\"reviewText\"].apply(lambda x: (x.str.count(\"[A-Z]\")/x.str.len()).mean())\n",
    "RpercentCap = RpercentCap.fillna(0).rename(\"Review_Percent_Uppercase\")\n",
    "\n",
    "SpercentCap = x.groupby('asin')[\"summary\"].apply(lambda x: (x.str.count(\"[A-Z]\")/x.str.len()).mean())\n",
    "SpercentCap = SpercentCap.fillna(0).rename(\"Summary_Percent_Uppercase\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Awesomeness Feature: # times the word \"awesome\" is used per review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualAwesomeness = x.groupby('asin')[\"reviewText\"].apply(lambda x: (x.str.count(\"[Aa]wesome\")).mean())\n",
    "actualAwesomeness = actualAwesomeness.fillna(0).rename(\"Actual_Awesomeness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin\n",
       "0000B049F5B33CD310EB1AB236E20191    0.000000\n",
       "00018184A9EC4D270219A296B2580303    0.055556\n",
       "000281A9CAC43FF1F335726A390636DA    0.000000\n",
       "00030884DF109F325638A6BFD5B13CFF    0.068966\n",
       "000325BA25966B5FC701D5D2B5DBA4E0    0.500000\n",
       "                                      ...   \n",
       "FFFDD3C72D23AF858D6E0ED92612370D    0.125000\n",
       "FFFDDE284A73B29B320381487EC7DE9E    0.000000\n",
       "FFFEB3EE2372807964F024707D50FB21    0.000000\n",
       "FFFF4545AB232D81D0F9B208388BB7AA    0.000000\n",
       "FFFF5A3D9CB0B40FF0FE6B95F05D26FE    0.185185\n",
       "Name: Actual_Awesomeness, Length: 73082, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualAwesomeness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function for sentiment analysis testing\n",
    "def review_sentiment(text):\n",
    "    sia = sentiment.SentimentIntensityAnalyzer()\n",
    "    return sia.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "## just some examples to gut check\n",
    "# print(review_sentiment(\"Ugh, what a terrible, horrible, no good, very bad day\"))\n",
    "# print(review_sentiment(\"I went to the store today\"))\n",
    "# print(review_sentiment(\"I absolutely love my favorite best friend\"))\n",
    "\n",
    "import string\n",
    "def preprocess(text):\n",
    "    try:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = \"\".join([char for char in text.lower() if char not in string.punctuation])\n",
    "        words = [word for word in word_tokenize(text) if word not in stopwords.words(\"english\")]\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in words]\n",
    "        return ' '.join(tokens)\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"processedTest\"] = x[\"reviewText\"].apply(preprocess)\n",
    "x[\"processedTest\"].to_json(\"../processedReviews.json\")\n",
    "x[\"processedSums\"] = x[\"summary\"].apply(preprocess)\n",
    "x[\"processedSums\"].to_json(\"../processedSummary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from the jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "revtext = pd.read_json(\"../processedReviews.json\",typ='series')\n",
    "revtext.to_frame('processedText')\n",
    "x[\"processedText\"] = revtext.fillna(\"\")\n",
    "\n",
    "sumtext = pd.read_json(\"../processedReviews.json\",typ='series')\n",
    "sumtext.to_frame('processedText')\n",
    "x[\"processedSums\"] = sumtext.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>image</th>\n",
       "      <th>processedText</th>\n",
       "      <th>processedSums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6673F1740E03573BCD64238FE711FC69</td>\n",
       "      <td>9C856D4A18E1355783B3B28B7ECC1848</td>\n",
       "      <td>1451520000</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>12 31, 2015</td>\n",
       "      <td>{'Format:': ' MP3 Music'}</td>\n",
       "      <td>8D88BB79AAC50277AEE82FCFD77F6744</td>\n",
       "      <td>Finding the Beatles all over again - and bette...</td>\n",
       "      <td>I sit listening - with my jaw to the floor - H...</td>\n",
       "      <td>None</td>\n",
       "      <td>finding beatles better ever im huge beatles fa...</td>\n",
       "      <td>finding beatles better ever im huge beatles fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>690819436E20BB31657AF6B58B984DD4</td>\n",
       "      <td>6E9ABBD26A27C2B2851D1EC34A01CBDC</td>\n",
       "      <td>1113523200</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>04 15, 2005</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>8DC0611245A871AC51BBEEBB85F33A58</td>\n",
       "      <td>These guys can sing!  Such classic tunes...poi...</td>\n",
       "      <td>Under Appreciated....</td>\n",
       "      <td>None</td>\n",
       "      <td>guys sing classic tunespoignant painful heartf...</td>\n",
       "      <td>guys sing classic tunespoignant painful heartf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A680D4753F0CEA2252C168A6ACB2B623</td>\n",
       "      <td>B637C3C93E61094474710F456928BE9F</td>\n",
       "      <td>1126137600</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>09 8, 2005</td>\n",
       "      <td>None</td>\n",
       "      <td>2259386624CFA0EC53A75A50A9BB57A5</td>\n",
       "      <td>Snoop Doggy Dogg made a classic album, DoggySt...</td>\n",
       "      <td>DoggyStyle</td>\n",
       "      <td>None</td>\n",
       "      <td>snoop doggy dogg made classic album doggystyle...</td>\n",
       "      <td>snoop doggy dogg made classic album doggystyle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F4A966F1FA340B16651D676BC246D227</td>\n",
       "      <td>AA7918E9410D650A076221C7B2934A09</td>\n",
       "      <td>954979200</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>04 6, 2000</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>7A65A155C993535BC99CBCB39E7161B5</td>\n",
       "      <td>Stevie Nicks Has had Her Moments. I Like Some ...</td>\n",
       "      <td>Pretty Good but a Bit Dated</td>\n",
       "      <td>None</td>\n",
       "      <td>stevie nicks moments like solo work love fleet...</td>\n",
       "      <td>stevie nicks moments like solo work love fleet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EF59DAF0C00319A48D4784266FD157EE</td>\n",
       "      <td>2293C9B7950A3356B95828419A677720</td>\n",
       "      <td>1477958400</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>11 1, 2016</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>C69A09446009C500B1364B7DB5510497</td>\n",
       "      <td>Great cd.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>None</td>\n",
       "      <td>great cd</td>\n",
       "      <td>great cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>14673A3D627445E270EBD9D11D2F70DD</td>\n",
       "      <td>9C84E3EFF58B759FE040B8938E6BD3DE</td>\n",
       "      <td>1460764800</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>04 16, 2016</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>1BBF7C11163C6DC130DD1EE87152CFD9</td>\n",
       "      <td>Same review as Vol. 1:  Super jamming!  Inspir...</td>\n",
       "      <td>Super jamming! Inspired me to get my guitar ou...</td>\n",
       "      <td>None</td>\n",
       "      <td>review vol 1 super jamming inspired get guitar...</td>\n",
       "      <td>review vol 1 super jamming inspired get guitar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>35A0CA6AE8C14595607D38DAC6525752</td>\n",
       "      <td>3ED9CD1EC55F0D896F93DA465C4712A9</td>\n",
       "      <td>1420243200</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>01 3, 2015</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>17AD55A9B8384777496330D23E59D520</td>\n",
       "      <td>WONDERFUL PURCHASE, \"Linda Rondstadt: The Coll...</td>\n",
       "      <td>WONDERFUL PURCHASE, \"Linda Rondstadt</td>\n",
       "      <td>None</td>\n",
       "      <td>wonderful purchase linda rondstadt collection ...</td>\n",
       "      <td>wonderful purchase linda rondstadt collection ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1C2F7451F06F0C2958694833095CB947</td>\n",
       "      <td>BA489C468556F643565413143979D571</td>\n",
       "      <td>1388966400</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>01 6, 2014</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>429889A95D8338A1312654487D673DAA</td>\n",
       "      <td>THIS MUSIC IS NICE. I MEAN WHAT MORE CAN I SAY...</td>\n",
       "      <td>NICE MUSIC</td>\n",
       "      <td>None</td>\n",
       "      <td>music nice mean say everything comes quality vibe</td>\n",
       "      <td>music nice mean say everything comes quality vibe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>C3D898B23687DE2EBB9350FE17F8CD24</td>\n",
       "      <td>FCF6C84C748B7E345693A45636118FAB</td>\n",
       "      <td>1127174400</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>09 20, 2005</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>3EA8FAFD8BB387929FBB53DDF4C8DAF9</td>\n",
       "      <td>I  loved listening to the music of Barbara Str...</td>\n",
       "      <td>Barbara and Barry make musical magic together</td>\n",
       "      <td>None</td>\n",
       "      <td>loved listening music barbara streisand barry ...</td>\n",
       "      <td>loved listening music barbara streisand barry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>C9C1C13DAEBB5E688BE6E3B81C1111D6</td>\n",
       "      <td>98C75F3AC4F6AAFD0585CB2EBDB1C81F</td>\n",
       "      <td>1517270400</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>01 30, 2018</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>B46E2A2B5F3F541CC9D326CB7B2EAA50</td>\n",
       "      <td>Great music</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>None</td>\n",
       "      <td>great music</td>\n",
       "      <td>great music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  asin                        reviewerID  \\\n",
       "0     6673F1740E03573BCD64238FE711FC69  9C856D4A18E1355783B3B28B7ECC1848   \n",
       "1     690819436E20BB31657AF6B58B984DD4  6E9ABBD26A27C2B2851D1EC34A01CBDC   \n",
       "2     A680D4753F0CEA2252C168A6ACB2B623  B637C3C93E61094474710F456928BE9F   \n",
       "3     F4A966F1FA340B16651D676BC246D227  AA7918E9410D650A076221C7B2934A09   \n",
       "4     EF59DAF0C00319A48D4784266FD157EE  2293C9B7950A3356B95828419A677720   \n",
       "...                                ...                               ...   \n",
       "1995  14673A3D627445E270EBD9D11D2F70DD  9C84E3EFF58B759FE040B8938E6BD3DE   \n",
       "1996  35A0CA6AE8C14595607D38DAC6525752  3ED9CD1EC55F0D896F93DA465C4712A9   \n",
       "1997  1C2F7451F06F0C2958694833095CB947  BA489C468556F643565413143979D571   \n",
       "1998  C3D898B23687DE2EBB9350FE17F8CD24  FCF6C84C748B7E345693A45636118FAB   \n",
       "1999  C9C1C13DAEBB5E688BE6E3B81C1111D6  98C75F3AC4F6AAFD0585CB2EBDB1C81F   \n",
       "\n",
       "      unixReviewTime  vote  verified   reviewTime                      style  \\\n",
       "0         1451520000     9      True  12 31, 2015  {'Format:': ' MP3 Music'}   \n",
       "1         1113523200     9     False  04 15, 2005   {'Format:': ' Audio CD'}   \n",
       "2         1126137600  None     False   09 8, 2005                       None   \n",
       "3          954979200  None     False   04 6, 2000   {'Format:': ' Audio CD'}   \n",
       "4         1477958400  None      True   11 1, 2016   {'Format:': ' Audio CD'}   \n",
       "...              ...   ...       ...          ...                        ...   \n",
       "1995      1460764800  None      True  04 16, 2016   {'Format:': ' Audio CD'}   \n",
       "1996      1420243200     3      True   01 3, 2015   {'Format:': ' Audio CD'}   \n",
       "1997      1388966400  None      True   01 6, 2014   {'Format:': ' Audio CD'}   \n",
       "1998      1127174400    10     False  09 20, 2005   {'Format:': ' Audio CD'}   \n",
       "1999      1517270400  None      True  01 30, 2018   {'Format:': ' Audio CD'}   \n",
       "\n",
       "                          reviewerName  \\\n",
       "0     8D88BB79AAC50277AEE82FCFD77F6744   \n",
       "1     8DC0611245A871AC51BBEEBB85F33A58   \n",
       "2     2259386624CFA0EC53A75A50A9BB57A5   \n",
       "3     7A65A155C993535BC99CBCB39E7161B5   \n",
       "4     C69A09446009C500B1364B7DB5510497   \n",
       "...                                ...   \n",
       "1995  1BBF7C11163C6DC130DD1EE87152CFD9   \n",
       "1996  17AD55A9B8384777496330D23E59D520   \n",
       "1997  429889A95D8338A1312654487D673DAA   \n",
       "1998  3EA8FAFD8BB387929FBB53DDF4C8DAF9   \n",
       "1999  B46E2A2B5F3F541CC9D326CB7B2EAA50   \n",
       "\n",
       "                                             reviewText  \\\n",
       "0     Finding the Beatles all over again - and bette...   \n",
       "1     These guys can sing!  Such classic tunes...poi...   \n",
       "2     Snoop Doggy Dogg made a classic album, DoggySt...   \n",
       "3     Stevie Nicks Has had Her Moments. I Like Some ...   \n",
       "4                                             Great cd.   \n",
       "...                                                 ...   \n",
       "1995  Same review as Vol. 1:  Super jamming!  Inspir...   \n",
       "1996  WONDERFUL PURCHASE, \"Linda Rondstadt: The Coll...   \n",
       "1997  THIS MUSIC IS NICE. I MEAN WHAT MORE CAN I SAY...   \n",
       "1998  I  loved listening to the music of Barbara Str...   \n",
       "1999                                        Great music   \n",
       "\n",
       "                                                summary image  \\\n",
       "0     I sit listening - with my jaw to the floor - H...  None   \n",
       "1                                 Under Appreciated....  None   \n",
       "2                                            DoggyStyle  None   \n",
       "3                           Pretty Good but a Bit Dated  None   \n",
       "4                                            Five Stars  None   \n",
       "...                                                 ...   ...   \n",
       "1995  Super jamming! Inspired me to get my guitar ou...  None   \n",
       "1996               WONDERFUL PURCHASE, \"Linda Rondstadt  None   \n",
       "1997                                         NICE MUSIC  None   \n",
       "1998      Barbara and Barry make musical magic together  None   \n",
       "1999                                         Five Stars  None   \n",
       "\n",
       "                                          processedText  \\\n",
       "0     finding beatles better ever im huge beatles fa...   \n",
       "1     guys sing classic tunespoignant painful heartf...   \n",
       "2     snoop doggy dogg made classic album doggystyle...   \n",
       "3     stevie nicks moments like solo work love fleet...   \n",
       "4                                              great cd   \n",
       "...                                                 ...   \n",
       "1995  review vol 1 super jamming inspired get guitar...   \n",
       "1996  wonderful purchase linda rondstadt collection ...   \n",
       "1997  music nice mean say everything comes quality vibe   \n",
       "1998  loved listening music barbara streisand barry ...   \n",
       "1999                                        great music   \n",
       "\n",
       "                                          processedSums  \n",
       "0     finding beatles better ever im huge beatles fa...  \n",
       "1     guys sing classic tunespoignant painful heartf...  \n",
       "2     snoop doggy dogg made classic album doggystyle...  \n",
       "3     stevie nicks moments like solo work love fleet...  \n",
       "4                                              great cd  \n",
       "...                                                 ...  \n",
       "1995  review vol 1 super jamming inspired get guitar...  \n",
       "1996  wonderful purchase linda rondstadt collection ...  \n",
       "1997  music nice mean say everything comes quality vibe  \n",
       "1998  loved listening music barbara streisand barry ...  \n",
       "1999                                        great music  \n",
       "\n",
       "[2000 rows x 13 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = x[:2000]\n",
    "ts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply sentiment analysis to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9p/sh_j3mrj2z374f2jzhy0z5mm0000gn/T/ipykernel_23720/2077047471.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ts[\"sumsent\"] = ts[\"processedSums\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "asin\n",
       "001D103D75A5694360941BEC51CEDAAA    0.8176\n",
       "002A2BBBB4571D357775F637CCCEB524    0.9062\n",
       "002DBFFDFE2E1C6C0BF01EB3BD2FD240    0.5719\n",
       "00734D25B89256B1F28189D85DC69DAA    0.8883\n",
       "0075BB016BA9DDD97B73646837308B55    0.9600\n",
       "                                     ...  \n",
       "FF842E4E26D4CC326384241595AF6C7C    0.8481\n",
       "FF879042885BA878431BED1BEA88DE5E    0.9709\n",
       "FF958322E74B2D83CEEA505960262354    0.9943\n",
       "FFA4EF1D77F95F89DE59138D51BC29C2    0.5271\n",
       "FFF6441225687D6E53F1C7962666D5D0    0.5719\n",
       "Name: sumsent, Length: 1847, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = sentiment.SentimentIntensityAnalyzer()\n",
    "ts[\"sumsent\"] = ts[\"processedSums\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n",
    "ts.groupby(\"asin\").mean()[\"sumsent\"]\n",
    "# Rtest = Rtest.rename(\"Review_Avg_Sentiment\")\n",
    "\n",
    "# Stest = x.groupby('asin')[\"processedSums\"].fillna(\"\").apply(lambda x: np.mean(sia.polarity_scores(x)[\"compound\"]))\n",
    "# Stest = Stest.rename(\"Summary_Avg_Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = sentiment.SentimentIntensityAnalyzer()\n",
    "x[\"rsent\"] = x[\"processedText\"].apply(lambda x: np.mean(sia.polarity_scores(x)[\"compound\"]))\n",
    "RavgSentiment = x.groupby(\"asin\").mean()[\"rsent\"]\n",
    "RavgSentiment = RavgSentiment.rename(\"Review_Avg_Sentiment\")\n",
    "\n",
    "\n",
    "sia = sentiment.SentimentIntensityAnalyzer()\n",
    "x['sumsent'] = x[\"processedSums\"].apply(lambda x: np.mean(sia.polarity_scores(x)[\"compound\"]))\n",
    "SavgSentiment = x.groupby(\"asin\").mean()[\"sumsent\"]\n",
    "SavgSentiment = SavgSentiment.rename(\"Summary_Avg_Sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin\n",
       "0000B049F5B33CD310EB1AB236E20191    0.880950\n",
       "00018184A9EC4D270219A296B2580303    0.647539\n",
       "000281A9CAC43FF1F335726A390636DA    0.688850\n",
       "00030884DF109F325638A6BFD5B13CFF    0.622297\n",
       "000325BA25966B5FC701D5D2B5DBA4E0    0.768700\n",
       "                                      ...   \n",
       "FFFDD3C72D23AF858D6E0ED92612370D    0.606214\n",
       "FFFDDE284A73B29B320381487EC7DE9E    0.955075\n",
       "FFFEB3EE2372807964F024707D50FB21    0.961100\n",
       "FFFF4545AB232D81D0F9B208388BB7AA    0.691300\n",
       "FFFF5A3D9CB0B40FF0FE6B95F05D26FE    0.322115\n",
       "Name: Review_Avg_Sentiment, Length: 73082, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RavgSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>cd</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>music</th>\n",
       "      <th>one</th>\n",
       "      <th>song</th>\n",
       "      <th>songs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000B049F5B33CD310EB1AB236E20191</th>\n",
       "      <td>0.103945</td>\n",
       "      <td>0.357921</td>\n",
       "      <td>0.140438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047707</td>\n",
       "      <td>0.650598</td>\n",
       "      <td>0.146021</td>\n",
       "      <td>0.092346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00018184A9EC4D270219A296B2580303</th>\n",
       "      <td>0.078173</td>\n",
       "      <td>0.383805</td>\n",
       "      <td>0.097147</td>\n",
       "      <td>0.164038</td>\n",
       "      <td>0.186362</td>\n",
       "      <td>0.198336</td>\n",
       "      <td>0.165989</td>\n",
       "      <td>0.311123</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.083888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000281A9CAC43FF1F335726A390636DA</th>\n",
       "      <td>0.287603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172802</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.317977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078973</td>\n",
       "      <td>0.153875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00030884DF109F325638A6BFD5B13CFF</th>\n",
       "      <td>0.172072</td>\n",
       "      <td>0.112765</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.128254</td>\n",
       "      <td>0.151698</td>\n",
       "      <td>0.198789</td>\n",
       "      <td>0.117097</td>\n",
       "      <td>0.182168</td>\n",
       "      <td>0.009765</td>\n",
       "      <td>0.086507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000325BA25966B5FC701D5D2B5DBA4E0</th>\n",
       "      <td>0.122886</td>\n",
       "      <td>0.364342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168699</td>\n",
       "      <td>0.135864</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.138615</td>\n",
       "      <td>0.098620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FFFDD3C72D23AF858D6E0ED92612370D</th>\n",
       "      <td>0.437644</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.132988</td>\n",
       "      <td>0.182225</td>\n",
       "      <td>0.103807</td>\n",
       "      <td>0.040482</td>\n",
       "      <td>0.042317</td>\n",
       "      <td>0.125199</td>\n",
       "      <td>0.157424</td>\n",
       "      <td>0.217296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FFFDDE284A73B29B320381487EC7DE9E</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160313</td>\n",
       "      <td>0.161066</td>\n",
       "      <td>0.133889</td>\n",
       "      <td>0.093727</td>\n",
       "      <td>0.289807</td>\n",
       "      <td>0.261508</td>\n",
       "      <td>0.511966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FFFEB3EE2372807964F024707D50FB21</th>\n",
       "      <td>0.338402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392162</td>\n",
       "      <td>0.178449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220705</td>\n",
       "      <td>0.374920</td>\n",
       "      <td>0.174604</td>\n",
       "      <td>0.224379</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FFFF4545AB232D81D0F9B208388BB7AA</th>\n",
       "      <td>0.609609</td>\n",
       "      <td>0.103663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061063</td>\n",
       "      <td>0.102653</td>\n",
       "      <td>0.040864</td>\n",
       "      <td>0.062983</td>\n",
       "      <td>0.193716</td>\n",
       "      <td>0.077752</td>\n",
       "      <td>0.036182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FFFF5A3D9CB0B40FF0FE6B95F05D26FE</th>\n",
       "      <td>0.253210</td>\n",
       "      <td>0.116739</td>\n",
       "      <td>0.339705</td>\n",
       "      <td>0.046746</td>\n",
       "      <td>0.249603</td>\n",
       "      <td>0.082942</td>\n",
       "      <td>0.123684</td>\n",
       "      <td>0.089237</td>\n",
       "      <td>0.177065</td>\n",
       "      <td>0.190702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73082 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     album        cd      good     great  \\\n",
       "asin                                                                       \n",
       "0000B049F5B33CD310EB1AB236E20191  0.103945  0.357921  0.140438  0.000000   \n",
       "00018184A9EC4D270219A296B2580303  0.078173  0.383805  0.097147  0.164038   \n",
       "000281A9CAC43FF1F335726A390636DA  0.287603  0.000000  0.172802  0.250000   \n",
       "00030884DF109F325638A6BFD5B13CFF  0.172072  0.112765  0.062137  0.128254   \n",
       "000325BA25966B5FC701D5D2B5DBA4E0  0.122886  0.364342  0.000000  0.168699   \n",
       "...                                    ...       ...       ...       ...   \n",
       "FFFDD3C72D23AF858D6E0ED92612370D  0.437644  0.062684  0.132988  0.182225   \n",
       "FFFDDE284A73B29B320381487EC7DE9E  0.000000  0.160313  0.161066  0.133889   \n",
       "FFFEB3EE2372807964F024707D50FB21  0.338402  0.000000  0.392162  0.178449   \n",
       "FFFF4545AB232D81D0F9B208388BB7AA  0.609609  0.103663  0.000000  0.061063   \n",
       "FFFF5A3D9CB0B40FF0FE6B95F05D26FE  0.253210  0.116739  0.339705  0.046746   \n",
       "\n",
       "                                      like      love     music       one  \\\n",
       "asin                                                                       \n",
       "0000B049F5B33CD310EB1AB236E20191  0.047707  0.650598  0.146021  0.092346   \n",
       "00018184A9EC4D270219A296B2580303  0.186362  0.198336  0.165989  0.311123   \n",
       "000281A9CAC43FF1F335726A390636DA  0.317977  0.000000  0.078973  0.153875   \n",
       "00030884DF109F325638A6BFD5B13CFF  0.151698  0.198789  0.117097  0.182168   \n",
       "000325BA25966B5FC701D5D2B5DBA4E0  0.135864  0.250000  0.138615  0.098620   \n",
       "...                                    ...       ...       ...       ...   \n",
       "FFFDD3C72D23AF858D6E0ED92612370D  0.103807  0.040482  0.042317  0.125199   \n",
       "FFFDDE284A73B29B320381487EC7DE9E  0.093727  0.289807  0.261508  0.511966   \n",
       "FFFEB3EE2372807964F024707D50FB21  0.000000  0.220705  0.374920  0.174604   \n",
       "FFFF4545AB232D81D0F9B208388BB7AA  0.102653  0.040864  0.062983  0.193716   \n",
       "FFFF5A3D9CB0B40FF0FE6B95F05D26FE  0.249603  0.082942  0.123684  0.089237   \n",
       "\n",
       "                                      song     songs  \n",
       "asin                                                  \n",
       "0000B049F5B33CD310EB1AB236E20191  0.000000  0.070214  \n",
       "00018184A9EC4D270219A296B2580303  0.059100  0.083888  \n",
       "000281A9CAC43FF1F335726A390636DA  0.000000  0.000000  \n",
       "00030884DF109F325638A6BFD5B13CFF  0.009765  0.086507  \n",
       "000325BA25966B5FC701D5D2B5DBA4E0  0.000000  0.173658  \n",
       "...                                    ...       ...  \n",
       "FFFDD3C72D23AF858D6E0ED92612370D  0.157424  0.217296  \n",
       "FFFDDE284A73B29B320381487EC7DE9E  0.000000  0.000000  \n",
       "FFFEB3EE2372807964F024707D50FB21  0.224379  0.000000  \n",
       "FFFF4545AB232D81D0F9B208388BB7AA  0.077752  0.036182  \n",
       "FFFF5A3D9CB0B40FF0FE6B95F05D26FE  0.177065  0.190702  \n",
       "\n",
       "[73082 rows x 10 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=10)\n",
    "# \n",
    "# x[\"processedText\"] = revtext\n",
    "tfidf_DF = x[[\"asin\",\"processedText\"]]\n",
    "\n",
    "\n",
    "\n",
    "# tfidf_DF[\"processedText\"] = \n",
    "# tfidf_DF[\"processedTest\"] = tfidf_DF[\"processedTest\"].fillna(\"\")\n",
    "# tfidf_DF[\"processedRevs\"] = tfidf_DF[\"reviewText\"].fillna(\"\").apply(preprocess)\n",
    "\n",
    "tfidf.fit_transform(tfidf_DF[\"processedText\"])\n",
    "# tfidffeatures.toarray()\n",
    "feature_names = tfidf.get_feature_names()\n",
    "tfidfarray = tfidf.transform(tfidf_DF[\"processedText\"]).toarray()\n",
    "\n",
    "featuredf = pd.DataFrame(tfidfarray,columns = feature_names)\n",
    "tfidf_DF = pd.concat([tfidf_DF,featuredf],axis=1)\n",
    "tfidfFeature = tfidf_DF.groupby(\"asin\")[feature_names].mean()\n",
    "\n",
    "tfidfFeature\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing prep\n",
    "\n",
    "Feature vectors must have format: col 1 as 'asin'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently using features:\n",
    "\n",
    "Name                    |     Column Name\n",
    "\n",
    "reviewCount                    Review_Count\n",
    "\n",
    "~~with_image_percentage          %_Image~~\n",
    "\n",
    "percent_verified               %_Verified\n",
    "\n",
    "total_votes                    Total_Votes\n",
    "\n",
    "reviewlength                   Review_Length\n",
    "\n",
    "summarylength                  Summary_Length\n",
    "\n",
    "RpercentCap                    Review_%_Uppercase\n",
    "\n",
    "SpercentCap                    Summary_%_Uppercase\n",
    "\n",
    "~~actualAwesomeness              Actual_Awesomeness~~\n",
    "\n",
    "RavgSentiment                  Review_Avg_Sentiment\n",
    "\n",
    "SavgSentiment                  Summary_Avg_Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all individual features into one dataFrame\n",
    "\n",
    "#enter any features to be combined here! \n",
    "#   They must be pd dataFrames with the 'asin' column for this to work\n",
    "features = [reviewCount,percent_verified,total_votes,reviewlength,summarylength,RpercentCap,SpercentCap,RavgSentiment,SavgSentiment]\n",
    "\n",
    "z = x['asin']\n",
    "for f in features:\n",
    "    z = pd.merge(z,f,'inner','asin')\n",
    "\n",
    "for i in range(tfidfFeature.shape[1]):\n",
    "    z = pd.merge(z,tfidfFeature[feature_names[i]],'inner','asin')\n",
    "\n",
    "\n",
    "\n",
    "#combine resultant data with correct answers \n",
    "temp = pd.merge(z,y,'inner','asin') \n",
    "temp = temp.groupby(\"asin\").mean()\n",
    "\n",
    "\n",
    "#split into features (x) and awesomeness (y), which now row correspond\n",
    "merged_x = temp.drop(['awesomeness'], axis=1)\n",
    "merged_y = temp[\"awesomeness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Count</th>\n",
       "      <th>%_Verified</th>\n",
       "      <th>Total_Votes</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Summary_Length</th>\n",
       "      <th>Review_Percent_Uppercase</th>\n",
       "      <th>Summary_Percent_Uppercase</th>\n",
       "      <th>album</th>\n",
       "      <th>cd</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>music</th>\n",
       "      <th>one</th>\n",
       "      <th>song</th>\n",
       "      <th>songs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000B049F5B33CD310EB1AB236E20191</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>88.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.210796</td>\n",
       "      <td>0.503689</td>\n",
       "      <td>0.103945</td>\n",
       "      <td>0.357921</td>\n",
       "      <td>0.140438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047707</td>\n",
       "      <td>0.650598</td>\n",
       "      <td>0.146021</td>\n",
       "      <td>0.092346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00018184A9EC4D270219A296B2580303</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>45.0</td>\n",
       "      <td>235.222222</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>0.076743</td>\n",
       "      <td>0.115941</td>\n",
       "      <td>0.078173</td>\n",
       "      <td>0.383805</td>\n",
       "      <td>0.097147</td>\n",
       "      <td>0.164038</td>\n",
       "      <td>0.186362</td>\n",
       "      <td>0.198336</td>\n",
       "      <td>0.165989</td>\n",
       "      <td>0.311123</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.083888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000281A9CAC43FF1F335726A390636DA</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>130.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.086681</td>\n",
       "      <td>0.153030</td>\n",
       "      <td>0.287603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172802</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.317977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078973</td>\n",
       "      <td>0.153875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00030884DF109F325638A6BFD5B13CFF</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.655172</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.059310</td>\n",
       "      <td>0.121813</td>\n",
       "      <td>0.172072</td>\n",
       "      <td>0.112765</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.128254</td>\n",
       "      <td>0.151698</td>\n",
       "      <td>0.198789</td>\n",
       "      <td>0.117097</td>\n",
       "      <td>0.182168</td>\n",
       "      <td>0.009765</td>\n",
       "      <td>0.086507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000325BA25966B5FC701D5D2B5DBA4E0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>91.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.038202</td>\n",
       "      <td>0.124301</td>\n",
       "      <td>0.122886</td>\n",
       "      <td>0.364342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168699</td>\n",
       "      <td>0.135864</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.138615</td>\n",
       "      <td>0.098620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00039B53F332D3A911B0B18F88051C80</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>27.0</td>\n",
       "      <td>155.666667</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>0.040205</td>\n",
       "      <td>0.102725</td>\n",
       "      <td>0.048509</td>\n",
       "      <td>0.058020</td>\n",
       "      <td>0.101119</td>\n",
       "      <td>0.164452</td>\n",
       "      <td>0.094307</td>\n",
       "      <td>0.174538</td>\n",
       "      <td>0.116126</td>\n",
       "      <td>0.257909</td>\n",
       "      <td>0.176273</td>\n",
       "      <td>0.388966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000449E7E71585B3F1A7EAE8B654B468</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.011419</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.221055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241748</td>\n",
       "      <td>0.730377</td>\n",
       "      <td>0.144171</td>\n",
       "      <td>0.249351</td>\n",
       "      <td>0.117587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004D01A4CED3FE007D35FB3933B3A6C</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.036524</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.503891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162743</td>\n",
       "      <td>0.385328</td>\n",
       "      <td>0.127109</td>\n",
       "      <td>0.239781</td>\n",
       "      <td>0.165035</td>\n",
       "      <td>0.099658</td>\n",
       "      <td>0.260891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00055F6EC779D818B9F33AA0885FC6E3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>160.500000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.061778</td>\n",
       "      <td>0.090441</td>\n",
       "      <td>0.236570</td>\n",
       "      <td>0.146833</td>\n",
       "      <td>0.147524</td>\n",
       "      <td>0.138489</td>\n",
       "      <td>0.081031</td>\n",
       "      <td>0.558581</td>\n",
       "      <td>0.138480</td>\n",
       "      <td>0.117637</td>\n",
       "      <td>0.097191</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000577BC760B4C7BD980939F0CB41F65</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>121.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.151552</td>\n",
       "      <td>0.249305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058402</td>\n",
       "      <td>0.276575</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>0.198404</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.208019</td>\n",
       "      <td>0.064449</td>\n",
       "      <td>0.028065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Review_Count  %_Verified  Total_Votes  \\\n",
       "asin                                                                      \n",
       "0000B049F5B33CD310EB1AB236E20191           4.0    0.500000          6.0   \n",
       "00018184A9EC4D270219A296B2580303          18.0    0.166667         45.0   \n",
       "000281A9CAC43FF1F335726A390636DA           4.0    0.750000          5.0   \n",
       "00030884DF109F325638A6BFD5B13CFF          29.0    0.586207         83.0   \n",
       "000325BA25966B5FC701D5D2B5DBA4E0           4.0    1.000000          7.0   \n",
       "00039B53F332D3A911B0B18F88051C80           6.0    0.666667         27.0   \n",
       "000449E7E71585B3F1A7EAE8B654B468           2.0    0.000000         30.0   \n",
       "0004D01A4CED3FE007D35FB3933B3A6C           5.0    0.400000         29.0   \n",
       "00055F6EC779D818B9F33AA0885FC6E3           4.0    0.750000         24.0   \n",
       "000577BC760B4C7BD980939F0CB41F65           4.0    0.750000         11.0   \n",
       "\n",
       "                                  Review_Length  Summary_Length  \\\n",
       "asin                                                              \n",
       "0000B049F5B33CD310EB1AB236E20191      88.500000        4.500000   \n",
       "00018184A9EC4D270219A296B2580303     235.222222        5.166667   \n",
       "000281A9CAC43FF1F335726A390636DA     130.500000        3.500000   \n",
       "00030884DF109F325638A6BFD5B13CFF      79.655172        5.000000   \n",
       "000325BA25966B5FC701D5D2B5DBA4E0      91.500000        3.000000   \n",
       "00039B53F332D3A911B0B18F88051C80     155.666667        4.833333   \n",
       "000449E7E71585B3F1A7EAE8B654B468     160.000000        6.000000   \n",
       "0004D01A4CED3FE007D35FB3933B3A6C     347.000000        5.800000   \n",
       "00055F6EC779D818B9F33AA0885FC6E3     160.500000       11.500000   \n",
       "000577BC760B4C7BD980939F0CB41F65     121.250000        3.000000   \n",
       "\n",
       "                                  Review_Percent_Uppercase  \\\n",
       "asin                                                         \n",
       "0000B049F5B33CD310EB1AB236E20191                  0.210796   \n",
       "00018184A9EC4D270219A296B2580303                  0.076743   \n",
       "000281A9CAC43FF1F335726A390636DA                  0.086681   \n",
       "00030884DF109F325638A6BFD5B13CFF                  0.059310   \n",
       "000325BA25966B5FC701D5D2B5DBA4E0                  0.038202   \n",
       "00039B53F332D3A911B0B18F88051C80                  0.040205   \n",
       "000449E7E71585B3F1A7EAE8B654B468                  0.011419   \n",
       "0004D01A4CED3FE007D35FB3933B3A6C                  0.036524   \n",
       "00055F6EC779D818B9F33AA0885FC6E3                  0.061778   \n",
       "000577BC760B4C7BD980939F0CB41F65                  0.028575   \n",
       "\n",
       "                                  Summary_Percent_Uppercase     album  \\\n",
       "asin                                                                    \n",
       "0000B049F5B33CD310EB1AB236E20191                   0.503689  0.103945   \n",
       "00018184A9EC4D270219A296B2580303                   0.115941  0.078173   \n",
       "000281A9CAC43FF1F335726A390636DA                   0.153030  0.287603   \n",
       "00030884DF109F325638A6BFD5B13CFF                   0.121813  0.172072   \n",
       "000325BA25966B5FC701D5D2B5DBA4E0                   0.124301  0.122886   \n",
       "00039B53F332D3A911B0B18F88051C80                   0.102725  0.048509   \n",
       "000449E7E71585B3F1A7EAE8B654B468                   0.022222  0.221055   \n",
       "0004D01A4CED3FE007D35FB3933B3A6C                   0.053700  0.503891   \n",
       "00055F6EC779D818B9F33AA0885FC6E3                   0.090441  0.236570   \n",
       "000577BC760B4C7BD980939F0CB41F65                   0.151552  0.249305   \n",
       "\n",
       "                                        cd      good     great      like  \\\n",
       "asin                                                                       \n",
       "0000B049F5B33CD310EB1AB236E20191  0.357921  0.140438  0.000000  0.047707   \n",
       "00018184A9EC4D270219A296B2580303  0.383805  0.097147  0.164038  0.186362   \n",
       "000281A9CAC43FF1F335726A390636DA  0.000000  0.172802  0.250000  0.317977   \n",
       "00030884DF109F325638A6BFD5B13CFF  0.112765  0.062137  0.128254  0.151698   \n",
       "000325BA25966B5FC701D5D2B5DBA4E0  0.364342  0.000000  0.168699  0.135864   \n",
       "00039B53F332D3A911B0B18F88051C80  0.058020  0.101119  0.164452  0.094307   \n",
       "000449E7E71585B3F1A7EAE8B654B468  0.000000  0.000000  0.241748  0.730377   \n",
       "0004D01A4CED3FE007D35FB3933B3A6C  0.000000  0.000000  0.162743  0.385328   \n",
       "00055F6EC779D818B9F33AA0885FC6E3  0.146833  0.147524  0.138489  0.081031   \n",
       "000577BC760B4C7BD980939F0CB41F65  0.000000  0.058402  0.276575  0.026866   \n",
       "\n",
       "                                      love     music       one      song  \\\n",
       "asin                                                                       \n",
       "0000B049F5B33CD310EB1AB236E20191  0.650598  0.146021  0.092346  0.000000   \n",
       "00018184A9EC4D270219A296B2580303  0.198336  0.165989  0.311123  0.059100   \n",
       "000281A9CAC43FF1F335726A390636DA  0.000000  0.078973  0.153875  0.000000   \n",
       "00030884DF109F325638A6BFD5B13CFF  0.198789  0.117097  0.182168  0.009765   \n",
       "000325BA25966B5FC701D5D2B5DBA4E0  0.250000  0.138615  0.098620  0.000000   \n",
       "00039B53F332D3A911B0B18F88051C80  0.174538  0.116126  0.257909  0.176273   \n",
       "000449E7E71585B3F1A7EAE8B654B468  0.144171  0.249351  0.117587  0.000000   \n",
       "0004D01A4CED3FE007D35FB3933B3A6C  0.127109  0.239781  0.165035  0.099658   \n",
       "00055F6EC779D818B9F33AA0885FC6E3  0.558581  0.138480  0.117637  0.097191   \n",
       "000577BC760B4C7BD980939F0CB41F65  0.198404  0.250000  0.208019  0.064449   \n",
       "\n",
       "                                     songs  \n",
       "asin                                        \n",
       "0000B049F5B33CD310EB1AB236E20191  0.070214  \n",
       "00018184A9EC4D270219A296B2580303  0.083888  \n",
       "000281A9CAC43FF1F335726A390636DA  0.000000  \n",
       "00030884DF109F325638A6BFD5B13CFF  0.086507  \n",
       "000325BA25966B5FC701D5D2B5DBA4E0  0.173658  \n",
       "00039B53F332D3A911B0B18F88051C80  0.388966  \n",
       "000449E7E71585B3F1A7EAE8B654B468  0.000000  \n",
       "0004D01A4CED3FE007D35FB3933B3A6C  0.260891  \n",
       "00055F6EC779D818B9F33AA0885FC6E3  0.000000  \n",
       "000577BC760B4C7BD980939F0CB41F65  0.028065  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_x[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "(choose one)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#kernel type\n",
    "#‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "kernel = 'poly'\n",
    "\n",
    "#if kernel type = 'poly', degree of poly\n",
    "degree = 4\n",
    "\n",
    "#whether to enable probability estimates (will slow it down a lot)\n",
    "probability = False\n",
    "\n",
    "#tau - penalty for errors is inversely proportional to C\n",
    "C = 0.75\n",
    "\n",
    "param_grid = [{'kernel': ['poly','rbf','sigmoid'],\n",
    "             'C': [0.25,0.5,0.75,1]}]\n",
    "\n",
    "# param_grid = [{'kernel': ['poly','rbf','sigmoid'],\n",
    "#             'C': [0.25,0.5,0.75,1]}]\n",
    "# -> {'C': 0.75, 'kernel': 'poly'}\n",
    "# f1: 0.694757392846268\n",
    "\n",
    "# param_grid = [{'degree': [2,3,4,5],\n",
    "#              'C': [0.7,0.75,0.8]}]\n",
    "# -> {'C': 0.75, 'degree': 4}\n",
    "# f1: 0.6805724352995487\n",
    "\n",
    "svm_model = svm.SVC(C=C, kernel=kernel, degree=degree, probability=probability)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "#choose from 'entropy', 'gini', 'log_loss'\n",
    "criterion = 'gini'\n",
    "\n",
    "    ###STOPPING CONDITIONS\n",
    "#max height/depth of the tree OR None if no limit\n",
    "max_depth = 5\n",
    "\n",
    "#if sat(N) < n_samples*this, don't try to split it any further\n",
    "min_samples_split = .05\n",
    "\n",
    "    ###OTHER\n",
    "#if min(sat(nodes after a split)) < n_samples*this, split not considered \n",
    "#       (aka model isnt allowed to create leaf nodes with < n_samples*this samples)\n",
    "#       (smooths the model, avoids splits like 2000 -> 1999 vs 1)\n",
    "min_samples_leaf = 0.01\n",
    "\n",
    "# param_grid = [{'criterion': ['entropy','gini','log_loss'],\n",
    "#             'max_depth': [None,5,10,15,20],\n",
    "#             'min_samples_split': [2,10,20,0.01,0.05,0.1,0.2],\n",
    "#             'min_samples_leaf':[2,10,20,0.01,0.05,0.1,0.2]}]\n",
    "# -> {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 0.01, 'min_samples_split': 0.05}\n",
    "# f1: 0.6440347415923986\n",
    "\n",
    "dtree_model = tree.DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree - See what it looks like! \n",
    "\n",
    "(only run if the model is a decision tree)\n",
    "\n",
    "*note: this trains the model on the whole dataset, so don't do before testing!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(131.52857142857144, 199.32, 'X[11] <= 0.129\\ngini = 0.498\\nsamples = 73082\\nvalue = [34205, 38877]'),\n",
       " Text(52.611428571428576, 163.07999999999998, 'X[1] <= 0.041\\ngini = 0.487\\nsamples = 39315\\nvalue = [16481, 22834]'),\n",
       " Text(19.13142857142857, 126.83999999999999, 'X[0] <= 2.5\\ngini = 0.493\\nsamples = 3997\\nvalue = [2231, 1766]'),\n",
       " Text(9.565714285714286, 90.6, 'gini = 0.5\\nsamples = 2147\\nvalue = [1085, 1062]'),\n",
       " Text(28.697142857142858, 90.6, 'gini = 0.471\\nsamples = 1850\\nvalue = [1146, 704]'),\n",
       " Text(86.09142857142857, 126.83999999999999, 'X[9] <= 0.142\\ngini = 0.481\\nsamples = 35318\\nvalue = [14250, 21068]'),\n",
       " Text(47.82857142857143, 90.6, 'X[12] <= 0.053\\ngini = 0.467\\nsamples = 22903\\nvalue = [8494, 14409]'),\n",
       " Text(28.697142857142858, 54.359999999999985, 'X[10] <= 0.221\\ngini = 0.48\\nsamples = 9373\\nvalue = [3754, 5619]'),\n",
       " Text(19.13142857142857, 18.119999999999976, 'gini = 0.488\\nsamples = 5812\\nvalue = [2462, 3350]'),\n",
       " Text(38.26285714285714, 18.119999999999976, 'gini = 0.462\\nsamples = 3561\\nvalue = [1292, 2269]'),\n",
       " Text(66.96000000000001, 54.359999999999985, 'X[11] <= 0.094\\ngini = 0.455\\nsamples = 13530\\nvalue = [4740, 8790]'),\n",
       " Text(57.394285714285715, 18.119999999999976, 'gini = 0.445\\nsamples = 10199\\nvalue = [3405, 6794]'),\n",
       " Text(76.52571428571429, 18.119999999999976, 'gini = 0.48\\nsamples = 3331\\nvalue = [1335, 1996]'),\n",
       " Text(124.35428571428571, 90.6, 'X[10] <= 0.211\\ngini = 0.497\\nsamples = 12415\\nvalue = [5756, 6659]'),\n",
       " Text(105.22285714285715, 54.359999999999985, 'X[16] <= 0.097\\ngini = 0.499\\nsamples = 8417\\nvalue = [4072, 4345]'),\n",
       " Text(95.65714285714286, 18.119999999999976, 'gini = 0.496\\nsamples = 4540\\nvalue = [2073, 2467]'),\n",
       " Text(114.78857142857143, 18.119999999999976, 'gini = 0.5\\nsamples = 3877\\nvalue = [1999, 1878]'),\n",
       " Text(143.4857142857143, 54.359999999999985, 'X[16] <= 0.144\\ngini = 0.488\\nsamples = 3998\\nvalue = [1684, 2314]'),\n",
       " Text(133.92000000000002, 18.119999999999976, 'gini = 0.48\\nsamples = 2792\\nvalue = [1117, 1675]'),\n",
       " Text(153.05142857142857, 18.119999999999976, 'gini = 0.498\\nsamples = 1206\\nvalue = [567, 639]'),\n",
       " Text(210.4457142857143, 163.07999999999998, 'X[1] <= 0.052\\ngini = 0.499\\nsamples = 33767\\nvalue = [17724, 16043]'),\n",
       " Text(162.61714285714285, 126.83999999999999, 'X[0] <= 2.5\\ngini = 0.47\\nsamples = 5805\\nvalue = [3617, 2188]'),\n",
       " Text(153.05142857142857, 90.6, 'gini = 0.491\\nsamples = 1993\\nvalue = [1129, 864]'),\n",
       " Text(172.18285714285713, 90.6, 'X[14] <= 0.256\\ngini = 0.453\\nsamples = 3812\\nvalue = [2488, 1324]'),\n",
       " Text(162.61714285714285, 54.359999999999985, 'gini = 0.437\\nsamples = 2547\\nvalue = [1727, 820]'),\n",
       " Text(181.74857142857144, 54.359999999999985, 'gini = 0.479\\nsamples = 1265\\nvalue = [761, 504]'),\n",
       " Text(258.2742857142857, 126.83999999999999, 'X[9] <= 0.094\\ngini = 0.5\\nsamples = 27962\\nvalue = [14107, 13855]'),\n",
       " Text(220.01142857142858, 90.6, 'X[7] <= 0.147\\ngini = 0.496\\nsamples = 11683\\nvalue = [5323, 6360]'),\n",
       " Text(200.88, 54.359999999999985, 'X[5] <= 0.033\\ngini = 0.487\\nsamples = 5153\\nvalue = [2160, 2993]'),\n",
       " Text(191.31428571428572, 18.119999999999976, 'gini = 0.496\\nsamples = 1599\\nvalue = [730, 869]'),\n",
       " Text(210.4457142857143, 18.119999999999976, 'gini = 0.481\\nsamples = 3554\\nvalue = [1430, 2124]'),\n",
       " Text(239.14285714285714, 54.359999999999985, 'X[10] <= 0.144\\ngini = 0.5\\nsamples = 6530\\nvalue = [3163, 3367]'),\n",
       " Text(229.57714285714286, 18.119999999999976, 'gini = 0.5\\nsamples = 3631\\nvalue = [1856, 1775]'),\n",
       " Text(248.70857142857142, 18.119999999999976, 'gini = 0.495\\nsamples = 2899\\nvalue = [1307, 1592]'),\n",
       " Text(296.53714285714284, 90.6, 'X[0] <= 10.5\\ngini = 0.497\\nsamples = 16279\\nvalue = [8784, 7495]'),\n",
       " Text(277.4057142857143, 54.359999999999985, 'X[1] <= 0.354\\ngini = 0.5\\nsamples = 10582\\nvalue = [5384, 5198]'),\n",
       " Text(267.84000000000003, 18.119999999999976, 'gini = 0.498\\nsamples = 3652\\nvalue = [1711, 1941]'),\n",
       " Text(286.9714285714286, 18.119999999999976, 'gini = 0.498\\nsamples = 6930\\nvalue = [3673, 3257]'),\n",
       " Text(315.66857142857145, 54.359999999999985, 'X[10] <= 0.197\\ngini = 0.481\\nsamples = 5697\\nvalue = [3400, 2297]'),\n",
       " Text(306.10285714285715, 18.119999999999976, 'gini = 0.47\\nsamples = 4465\\nvalue = [2778, 1687]'),\n",
       " Text(325.2342857142857, 18.119999999999976, 'gini = 0.5\\nsamples = 1232\\nvalue = [622, 610]')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtree_model.fit(merged_x,merged_y)\n",
    "tree.plot_tree(dtree_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#number of neighbors\n",
    "n_neighbors = 2500\n",
    "\n",
    "#do you want proximity to effect influence neighbors have or not\n",
    "# 'uniform' or 'distance'\n",
    "weights='distance'\n",
    "\n",
    "#leaf size passed to trees\n",
    "leaf_size=3\n",
    "\n",
    "# param_grid = [{'n_neighbors': [5,7,9,11],\n",
    "#             'weights': ['uniform','distance'],\n",
    "#             'leaf_size':[15,20,25,30]}] -> f1: 0.67, {'leaf_size': 15, 'n_neighbors': 11, 'weights': 'uniform'}\n",
    "\n",
    "# param_grid = [{'n_neighbors': [9,11,15,19,23],\n",
    "#              'weights': ['uniform','distance'],\n",
    "#              'leaf_size':[5,10,15,20]}] -> f1: 0.65, {'leaf_size': 5, 'n_neighbors': 23, 'weights': 'uniform'}\n",
    "\n",
    "# param_grid = [{'n_neighbors': [11,22,33,44,55],\n",
    "#              'weights': ['uniform','distance'],\n",
    "#              'leaf_size':[1,2,3,4,5,6,7,8,9,10,11,12]}] \n",
    "# -> {'leaf_size': 1, 'n_neighbors': 55, 'weights': 'uniform'}\n",
    "# f1: 0.63\n",
    "\n",
    "# param_grid = [{'n_neighbors': [11,22,33,44,55],\n",
    "#              'weights': ['uniform','distance'],\n",
    "#              'leaf_size':[1,2,3,4,5,6,7,8,9,10,11,12]}]\n",
    "# -> {'leaf_size': 3, 'n_neighbors': 55, 'weights': 'distance'}\n",
    "# f1: 0.6115\n",
    "\n",
    "# param_grid = [{'n_neighbors': [1000,1500,2000,2500]}]\n",
    "# -> {'n_neighbors': 2500}\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, leaf_size=leaf_size, n_jobs=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#norm of the penalty\n",
    "#‘l1’, ‘l2’, ‘elasticnet’, None\n",
    "penalty = 'l2'\n",
    "\n",
    "#inverse of regulation strength tau - how much do errors cost?\n",
    "C = 0.35\n",
    "\n",
    "#algorithm to compute optimization problem. Probs wont do much other than speed\n",
    "#‘lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’\n",
    "solver = 'sag'\n",
    "\n",
    "max_iter=500\n",
    "\n",
    "# param_grid = [{'penalty': ['l1','l2','elasticnet',None],\n",
    "#             'C': [0.25,0.5,0.75,1],\n",
    "#             'solver': ['lbfgs','newton-cg','newton-cholesky','sag','saga'],\n",
    "#             'max_iter': [1000,500,100]}]        \n",
    "# -> {'C': 0.5, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag'}\n",
    "# f1: 0.6916044272473679\n",
    "\n",
    "# param_grid = [{'C': [0.4,0.45,0.5,0.55,0.6],\n",
    "#             'solver': ['lbfgs','newton-cg','newton-cholesky','sag','saga'],\n",
    "#             'max_iter': [700,600,500,400,300]}]\n",
    "# -> {'C': 0.4, 'max_iter': 500, 'solver': 'sag'}\n",
    "# f1: 0.6915982039214981\n",
    "\n",
    "# param_grid = [{'C': [0.3,0.35,0.4,0.45]}]\n",
    "# -> {'C': 0.35}\n",
    "# f1: 0.6915982039214981\n",
    "\n",
    "regression_model = LogisticRegression(penalty=penalty, C=C, solver=solver, max_iter=max_iter, n_jobs=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try nonlinear regression by manipulating given features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to nonlinearly transform features!\n",
    "#np.sqrt, np.log, np.square\n",
    "f = np.sqrt\n",
    "\n",
    "merged_x = merged_x.apply(lambda x: f(x+1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#number of trees, int\n",
    "n_estimators=150\n",
    "\n",
    "#Criteria to determine split quality\n",
    "#“gini”, “entropy”, “log_loss”\n",
    "criterion = 'log_loss'\n",
    "\n",
    "#max depth of each tree, int or None for infinite\n",
    "max_depth = None\n",
    "\n",
    "#min #/% of samples to leave in a branch after a split\n",
    "min_samples_split = 0.25\n",
    "\n",
    "#min #/% of samples to be a leaf node\n",
    "min_samples_leaf = 0.4\n",
    "\n",
    "# param_grid = [{'n_estimators': [50,100,150],\n",
    "#             'criterion': ['gini','entropy','log_loss'],\n",
    "#             'max_depth':[None,10,15,20],\n",
    "#             'min_samples_split':[2,0.01,0.05,0.1,0.2],\n",
    "#             'min_samples_leaf':[2,0.01,0.05,0.1,0.2]}]\n",
    "# -> {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 0.2, 'min_samples_split': 0.2, 'n_estimators': 150}\n",
    "# f1: 0.686935866983373\n",
    "\n",
    "# param_grid = [{'n_estimators': [125,150,175,200],\n",
    "#             'min_samples_split':[.1,.2,.3],\n",
    "#             'min_samples_leaf':[.1,.2,.3]}]\n",
    "# -> {'min_samples_leaf': 0.3, 'min_samples_split': 0.2, 'n_estimators': 150}\n",
    "# f1: 0.6944863744763707\n",
    "            \n",
    "# param_grid = [{'n_estimators': [140,145,150,155,160],\n",
    "#             'min_samples_split':[.15,.2,.25],\n",
    "#             'min_samples_leaf':[.25,.3,.35,.4]}]\n",
    "# -> {'min_samples_leaf': 0.4, 'min_samples_split': 0.25, 'n_estimators': 150}\n",
    "# f1: 0.6944863744763707\n",
    "\n",
    "# param_grid = [{'min_samples_split':[0.15,0.175,0.2,0.225,0.25,0.275,0.3]}]\n",
    "# -> 0.6944863744763707\n",
    "# {'min_samples_split': 0.25}\n",
    "\n",
    "randomforest_model = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, n_jobs=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting!\n",
    "make a model better! goes into *boosted_model*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9p/sh_j3mrj2z374f2jzhy0z5mm0000gn/T/ipykernel_23720/2377133877.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#             'learning_rate': [1,2,3]}]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0madaboosted_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregression_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'estimator'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#model to build off of\n",
    "#estimator = model\n",
    "\n",
    "#max number of estimators to compute before terminating testing\n",
    "n_estimators = 20\n",
    "\n",
    "#weight applied to each classifier at each boosting iteration\n",
    "learning_rate = 1.0\n",
    "\n",
    "# param_grid = [{'n_estimators': [10,20,30],\n",
    "#             'learning_rate': [1,2,3]}]\n",
    "\n",
    "adaboosted_model = AdaBoostClassifier(estimator=regression_model, n_estimators=n_estimators, learning_rate=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HistGradientBoostingClassifier' from 'sklearn.ensemble' (/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9p/sh_j3mrj2z374f2jzhy0z5mm0000gn/T/ipykernel_23720/1925286765.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHistGradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#loss function to use in boosting process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#‘log_loss’, ‘auto’, ‘binary_crossentropy’/depreciated, ‘categorical_crossentropy’\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'log_loss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HistGradientBoostingClassifier' from 'sklearn.ensemble' (/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "#loss function to use in boosting process\n",
    "#‘log_loss’, ‘auto’, ‘binary_crossentropy’/depreciated, ‘categorical_crossentropy’\n",
    "loss = 'log_loss'\n",
    "\n",
    "#shrinkage - multiplicative value for leaves\n",
    "learning_rate=0.24\n",
    "\n",
    "#maximum iterations for boosting process\n",
    "max_iter=1\n",
    "\n",
    "#maximum leaf nodes/tree\n",
    "max_leaf_nodes=2\n",
    "\n",
    "#max depth/tree or None for infinite\n",
    "max_depth = None\n",
    "\n",
    "#min samples to be a leaf\n",
    "min_samples_leaf=15\n",
    "\n",
    "#regularization parameter, 0 for none\n",
    "l2_regularization=0\n",
    "\n",
    "# param_grid = [{'learning_rate': [0.1,0.3,0.5,0.7,1],\n",
    "#             'max_iter':[50,60],\n",
    "#             'max_leaf_nodes':[25,30,35,40],\n",
    "#             'max_depth':[None,10,15,20],\n",
    "#             'min_samples_leaf':[20,0.01,0.05,0.1,0.2],\n",
    "#             'l2_regularization':[0,0.1,0.2]}] \n",
    "# -> f1: 0.67, {'l2_regularization': 0, 'learning_rate': 0.3, 'max_depth': None, 'max_iter': 50, 'max_leaf_nodes': 25, 'min_samples_leaf': 20}\n",
    "\n",
    "# param_grid = [{'learning_rate': [0.2,0.25,0.3,0.35,0.4],\n",
    "#             'max_iter':[30,40,50],\n",
    "#             'max_leaf_nodes':[10,15,20,25],\n",
    "#             'min_samples_leaf':[10,15,20,25,30]}] \n",
    "# -> f1: 0.66 {'learning_rate': 0.3, 'max_iter': 30, 'max_leaf_nodes': 10, 'min_samples_leaf': 15}\n",
    "\n",
    "# param_grid = [{'learning_rate': [0.25,0.275,0.3,0.325,0.35],\n",
    "#             'max_iter':[1,10,20,30],\n",
    "#             'max_leaf_nodes':[2,4,6,8,10],\n",
    "#             'min_samples_leaf':[12,13,14,15,16,17,18]}] \n",
    "# -> f1: 0.68 {'learning_rate': 0.275, 'max_iter': 1, 'max_leaf_nodes': 4, 'min_samples_leaf': 14}\n",
    "\n",
    "# param_grid = [{'learning_rate': [0.265,0.27,0.275,0.28,0.285],\n",
    "#             'max_leaf_nodes':[2,3,4,5,6],\n",
    "#             'min_samples_leaf':[13,14,15]}] \n",
    "# -> f1: 0.68 {'learning_rate': 0.27, 'max_leaf_nodes': 3, 'min_samples_leaf': 15}\n",
    "\n",
    "# param_grid = [{'learning_rate': [0.26,0.2665,0.267,0.2675,0.268,0.2685,0.269,0.2695,0.27,0.2705,0.271,0.2715,0.272,0.2725],\n",
    "#              'max_leaf_nodes':[2,3,4],\n",
    "#              'min_samples_leaf':[13,14,15,16,17],\n",
    "#              'max_iter':[0,1,2,3,4,5,6,7,8,9,10]}] \n",
    "# -> f1: 0.684 {'learning_rate': 0.269, 'max_iter': 3, 'max_leaf_nodes': 2, 'min_samples_leaf': 16}\n",
    "\n",
    "# param_grid = [{'learning_rate': [0.26,0.2665,0.267],\n",
    "#              'max_leaf_nodes':[4,5,6,7,8],\n",
    "#              'min_samples_leaf':[13,14,15],\n",
    "#              'max_iter':[3,4,5]}] \n",
    "# -> {'learning_rate': 0.26, 'max_iter': 3, 'max_leaf_nodes': 4, 'min_samples_leaf': 15}\n",
    "# f1: 0.6831502199369314\n",
    "\n",
    "# param_grid = [{'learning_rate': [0.24,0.245,0.25,0.255,0.26],\n",
    "#              'max_leaf_nodes':[1,2,3,4,5],\n",
    "#              'min_samples_leaf':[15,16,17,18],\n",
    "#              'max_iter':[1,2,3,4]}] \n",
    "# -> {'learning_rate': 0.24, 'max_iter': 1, 'max_leaf_nodes': 2, 'min_samples_leaf': 15}\n",
    "# f1: 0.694\n",
    "\n",
    "gradient_boosted_model = HistGradientBoostingClassifier(loss=loss, learning_rate=learning_rate, max_iter=max_iter, max_leaf_nodes=max_leaf_nodes, max_depth=max_depth, min_samples_leaf=min_samples_leaf, l2_regularization=l2_regularization)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging (for speed!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#number of estimators\n",
    "n_estimators = 10\n",
    "\n",
    "bagged_model = BaggingClassifier(svm_model, max_features=1/n_estimators, n_estimators=n_estimators, n_jobs=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LATE FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "#which models to use for primary predictions\n",
    "estimators = [('forest',randomforest_model),('knn',knn_model),('dtree',dtree_model)]\n",
    "\n",
    "#which model to use for final prediction\n",
    "final_estimator = svm_model\n",
    "\n",
    "#k for cross validation for training of final_estimator\n",
    "cv = 10\n",
    "\n",
    "late_fused_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator,cv=cv,n_jobs=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard scaler pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('model', knn_model)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINED NODE FOR TESTING AND PRINTING BC IM LAZY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 672, in fit\n",
      "    return _fit_classifier(self, X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 338, in _fit_classifier\n",
      "    return super(RandomForestClassifier, self).fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 672, in fit\n",
      "    return _fit_classifier(self, X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 338, in _fit_classifier\n",
      "    return super(RandomForestClassifier, self).fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 672, in fit\n",
      "    return _fit_classifier(self, X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 338, in _fit_classifier\n",
      "    return super(RandomForestClassifier, self).fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 672, in fit\n",
      "    return _fit_classifier(self, X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 338, in _fit_classifier\n",
      "    return super(RandomForestClassifier, self).fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 672, in fit\n",
      "    return _fit_classifier(self, X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 338, in _fit_classifier\n",
      "    return super(RandomForestClassifier, self).fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 672, in fit\n",
      "    return _fit_classifier(self, X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 338, in _fit_classifier\n",
      "    return super(RandomForestClassifier, self).fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 672, in fit\n",
      "    return _fit_classifier(self, X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 338, in _fit_classifier\n",
      "    return super(RandomForestClassifier, self).fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 672, in fit\n",
      "    return _fit_classifier(self, X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 338, in _fit_classifier\n",
      "    return super(RandomForestClassifier, self).fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 672, in fit\n",
      "    return _fit_classifier(self, X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 338, in _fit_classifier\n",
      "    return super(RandomForestClassifier, self).fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\tAVG, STDEV TEST RESULTS\n",
      "----------------------------------------\n",
      "\t\tMEAN\t\tSTDEV\n",
      "f1:       \tnan\t\tnan\n",
      "accuracy: \tnan\t\tnan\n",
      "precision:\tnan\t\tnan\n",
      "recall:   \tnan\t\tnan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 672, in fit\n",
      "    return _fit_classifier(self, X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/ensemble/_forest.py\", line 338, in _fit_classifier\n",
      "    return super(RandomForestClassifier, self).fit(\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/maxrogal/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "#desired metrics\n",
    "scoring=['f1','accuracy','precision','recall']\n",
    "\n",
    "#number of \"folds\"\n",
    "k=10\n",
    "\n",
    "cv_results = cross_validate(randomforest_model, merged_x, merged_y, cv=k, scoring=scoring)\n",
    "\n",
    "# pretty print results\n",
    "hline = (\"-\"*40)\n",
    "\n",
    "#print means, stdevs\n",
    "print(hline+\"\\n\\tAVG, STDEV TEST RESULTS\\n\"+hline)\n",
    "print(\"\\t\\tMEAN\\t\\tSTDEV\")\n",
    "for m in scoring:\n",
    "        ind = (\"test_\"+m)\n",
    "        test = (m+\":\").ljust(10)\n",
    "        print(f\"{test}\\t{np.round(cv_results[ind].mean(),4)}\\t\\t{np.round(cv_results[ind].std(),4)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold testing \n",
    "\n",
    "(set model to variable *model*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#desired metrics\n",
    "scoring=['f1','accuracy','precision','recall']\n",
    "\n",
    "#number of \"folds\"\n",
    "k=10\n",
    "\n",
    "cv_results = cross_validate(model, merged_x, merged_y, cv=k, scoring=scoring)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hline = (\"-\"*40)\n",
    "\n",
    "#print means, stdevs\n",
    "print(hline+\"\\n\\tAVG, STDEV TEST RESULTS\\n\"+hline)\n",
    "print(\"\\t\\tMEAN\\t\\tSTDEV\")\n",
    "for m in scoring:\n",
    "        ind = (\"test_\"+m)\n",
    "        test = (m+\":\").ljust(10)\n",
    "        print(f\"{test}\\t{np.round(cv_results[ind].mean(),4)}\\t\\t{np.round(cv_results[ind].std(),4)}\")\n",
    "\n",
    "\n",
    "    ##print per test results (if you really want, uncomment)\n",
    "# print(\"\\n\")\n",
    "# print(hline+\"\\n\\tPER TEST RESULTS\\n\"+hline)\n",
    "# for i in range(k):\n",
    "#     print(f\"Test {i}:\")\n",
    "#     for m in scoring:\n",
    "#         ind = (\"test_\"+m)\n",
    "#         test = (m+\":\").ljust(10)\n",
    "#         print(f\"\\t{test} {np.round(cv_results[ind][i],5)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(merged_x, merged_y, test_size=0.5, random_state=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Searching for Best Parameters\n",
    "\n",
    "must have parameters for variable in *params*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(knn_model, param_grid=param_grid, scoring='f1', cv=10)\n",
    "grid_search.fit(x_train,y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.score(x_test,y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Halving random grid search (for speed up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "hg_search = HalvingGridSearchCV(knn_model, param_grid=param_grid, scoring='f1', cv=10)\n",
    "hg_search.fit(x_train,y_train)\n",
    "print(hg_search.best_params_)\n",
    "print(hg_search.score(x_test,y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False  True]\n",
      "[9 8 7 6 5 4 3 2 1]\n",
      "['Review_Count' '%_Verified' 'Total_Votes' 'Review_Avg_Sentiment'\n",
      " 'Summary_Avg_Sentiment' 'Review_Length' 'Summary_Length'\n",
      " 'Review_Percent_Uppercase' 'Summary_Percent_Uppercase']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "selector = RFECV(randomforest_model, step=1, cv=10) \n",
    "selector = selector.fit(merged_x,merged_y)\n",
    "print(selector.support_)\n",
    "print(selector.ranking_)\n",
    "print(selector.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "\n",
    "print(merged_x.shape)\n",
    "new_x = SelectKBest(chi2, k='all')\n",
    "absx = merged_x.apply(lambda x: x+1) #selectKBest requires all positive values, sentiment analysis is between -1 and 1 -> 0 and 2 now!\n",
    "out = new_x.fit_transform(absx, merged_y)\n",
    "print(new_x.scores_)\n",
    "print(new_x.feature_names_in_)\n",
    "print(out.shape)\n",
    "\n",
    "# SELECTKBEST: [3.25559172e+02 5.59255454e-03 2.75958219e+01 3.66946669e+02\n",
    "#  3.42079412e+01 4.36649522e+01 1.85080492e+04 6.30872323e+01\n",
    "#  7.68359033e-01 3.83305432e-01 1.04268202e-02]\n",
    "# -['Review_Count' '%_Image' '%_Verified' 'Total_Votes'\n",
    "#  'Review_Avg_Sentiment' 'Summary_Avg_Sentiment' 'Review_Length'\n",
    "#  'Summary_Length' 'Summary_Percent_Uppercase' 'Review_Percent_Uppercase'\n",
    "#  'Actual_Awesomeness']\n",
    "#-> RFECV: [1 3 1 1 1 1 1 1 1 2]\n",
    "\n",
    "# SO: \n",
    "# Seems like %_image, actual_awesomeness do the least. Percent_uppercases do the next worst.\n",
    "# -> lets try cutting them out!\n",
    "\n",
    "#->\n",
    "# [  325.55917172    27.59582185   366.94666861    34.20794125\n",
    "#     43.6649522  18508.04915683    63.08723227]\n",
    "# ['Review_Count' '%_Verified' 'Total_Votes' 'Review_Avg_Sentiment'\n",
    "#  'Summary_Avg_Sentiment' 'Review_Length' 'Summary_Length']\n",
    "# -> RFECV2: [4 1 5 1 1 3 2]\n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = randomforest_model.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_pred)\n",
    "AUROC = metrics.auc(fpr, tpr)\n",
    "\n",
    "disp = metrics.RocCurveDisplay(fpr=fpr,tpr=tpr,roc_auc=AUROC)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.tick_params(axis='x', colors='white') \n",
    "ax.tick_params(axis='y', colors='white') \n",
    "ax.spines['left'].set_color('white') \n",
    "ax.spines['bottom'].set_color('white') \n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.xlabel(\"X\",fontsize=20, color='white')\n",
    "plt.ylabel(\"Y\",fontsize=20, color='white')\n",
    "plt.title(\"Area Under ROC Curve\", fontsize = 20, color='white')\n",
    "\n",
    "disp.plot(ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Prediction for Test Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_json('CDs_and_Vinyl/test1/review_test.json')\n",
    "test_y = pd.read_json('CDs_and_Vinyl/test1/product_test.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun Variable Analyses! then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again, combine all individual features into one dataFrame\n",
    "\n",
    "features = [reviewCount,percent_verified,total_votes,RavgSentiment,SavgSentiment,reviewlength,summarylength,RpercentCap,SpercentCap]\n",
    "\n",
    "test_merged_x = x['asin']\n",
    "for f in features:\n",
    "    test_merged_x = pd.merge(test_merged_x,f,'inner','asin')\n",
    "test_merged_x = test_merged_x.groupby(\"asin\").mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "predictions = randomforest_model.predict(test_merged_x) \n",
    "\n",
    "# Rejoin to create output\n",
    "test_y.insert(1, \"predictions\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = pd.DataFrame(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output predictions to file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output predictions to file!\n",
    "  \n",
    "#turn predictions into json\n",
    "json_str = test_y.to_json()\n",
    "\n",
    "#output json to file\n",
    "with open('predictions.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
